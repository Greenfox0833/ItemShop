import json
import sys
import requests
from datetime import datetime, timezone, timedelta
from pathlib import Path

URL = "https://fortnitecontent-website-prod07.ol.epicgames.com/content/api/pages/fortnite-game/mp-item-shop"
PARAMS = {"lang": "ja"}
HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Accept": "application/json"
}

def dig_for_sections(obj):
    if isinstance(obj, dict):
        for k in ["shopSections", "sections", "sectionList", "ShopSections", "shop_sections"]:
            if k in obj and isinstance(obj[k], list):
                return obj[k]
        for v in obj.values():
            res = dig_for_sections(v)
            if res:
                return res
    elif isinstance(obj, list):
        for v in obj:
            res = dig_for_sections(v)
            if res:
                return res
    return None

def normalize_section(sec):
    # ãƒã‚¹ãƒˆï¼ˆsection / contentï¼‰ã‚’å¸å
    base = sec.get("section") or sec.get("content") or sec
    meta = base.get("metadata") or sec.get("metadata") or {}

    get = lambda *keys: next((base[k] for k in keys if isinstance(base, dict) and k in base), None)

    # --- stackRanks ã‚’é›†ç´„ï¼šç›´ä¸‹ / base / metadata / offerGroups[].stackRanks ---
    stackRanks_all = []
    for src in (sec.get("stackRanks"), base.get("stackRanks"), meta.get("stackRanks")):
        if isinstance(src, list):
            stackRanks_all.extend(src)

    # offerGroups å´ã® stackRanks ã‚‚è¿½åŠ 
    og_list = meta.get("offerGroups") or []
    for og in og_list:
        if isinstance(og, dict):
            ranks = og.get("stackRanks")
            if not ranks:
                ranks = (og.get("metadata") or {}).get("stackRanks")
            if isinstance(ranks, list):
                stackRanks_all.extend(ranks)

    # â‘  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® 2023-01-01 ã¯é™¤å¤–
    # â‘  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® 2023-01-01 ã¯é™¤å¤–ã—ã¤ã¤ã€ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«é–‹å§‹/çµ‚äº†ã‚’æ±ºå®š
    #    ã‚°ãƒ«ãƒ¼ãƒ—ã‚­ãƒ¼: (context, productTag)
    groups = {}
    for s in stackRanks_all:
        sd = s.get("startDate")
        if not sd or sd == "2023-01-01T00:00:00.000Z":
            continue
        key = (s.get("context"), s.get("productTag"))
        groups.setdefault(key, []).append(s)

    parsed_ranks = []
    for key, items in groups.items():
        # ISO8601æ–‡å­—åˆ—ãªã®ã§æ–‡å­—åˆ—ã‚½ãƒ¼ãƒˆã§OKï¼ˆå³å¯†ã«ã™ã‚‹ãªã‚‰ datetime ã«ã—ã¦ã‚‚è‰¯ã„ï¼‰
        items.sort(key=lambda x: x.get("startDate"))
        for i, cur in enumerate(items):
            nxt = items[i + 1] if i + 1 < len(items) else None
            parsed_ranks.append({
                # å‡ºåŠ›ã¯é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã®ã¿ï¼ˆçµ‚äº†æ—¥ã¯æ¬¡ã®é–‹å§‹æ—¥ã€æœ€å¾Œã¯ Noneï¼‰
                "startDate": cur.get("startDate"),
                "endDate":   nxt.get("startDate") if nxt else None,
            })


    # â‘¡ èƒŒæ™¯URLï¼ˆcustomTextureï¼‰
    bg = (meta.get("background") or {})
    custom_tex = bg.get("customTexture")

    # â‘¢ offerGroups ä»¶æ•°ï¼ˆåŒä¸€ sectionId å†…ã§ offerGroupId é‡è¤‡ã¯ 1 ã‚«ã‚¦ãƒ³ãƒˆã«é›†ç´„ï¼‰
    og_list = meta.get("offerGroups") or []
    unique_ids = set()
    no_id_count = 0
    for og in og_list:
        if not isinstance(og, dict):
            no_id_count += 1
            continue
        # é€šå¸¸ã¯ og["offerGroupId"] ã‚’å‚ç…§ã€‚å¿µã®ãŸã‚ metadata å´ã‚‚è¦‹ã‚‹ã€‚
        oid = og.get("offerGroupId")
        if not oid and isinstance(og.get("metadata"), dict):
            oid = og["metadata"].get("offerGroupId")
        if oid:
            unique_ids.add(str(oid))
        else:
            # ID ãŒç„¡ã„ã‚‚ã®ã¯å€‹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            no_id_count += 1
    offer_groups_count = len(unique_ids) + no_id_count

    # â‘£ textureMetadata ã®æœ‰ç„¡ã¨URLãƒªã‚¹ãƒˆï¼ˆä¿å­˜ç”¨ï¼‰
    texture_urls = []
    for og in og_list:
        md = (og.get("metadata") or {})
        tmetas = md.get("textureMetadata") or []
        for t in tmetas:
            val = t.get("value")
            if isinstance(val, str):
                texture_urls.append(val)
    has_texture_metadata = len(texture_urls) > 0
    # é‡è¤‡é™¤å»
    texture_urls = list(dict.fromkeys(texture_urls))

    # stackRanks ã®é–‹å§‹æ—¥ã ã‘ã‚’1ã¤å–ã‚‹
    start_date = None
    if parsed_ranks:
        try:
            start_date = min(r["startDate"] for r in parsed_ranks if r.get("startDate"))
        except ValueError:
            start_date = None

    return {
        "sectionId":          get("sectionId", "sectionID", "id", "section_id", "name"),
        "displayName":        get("displayName", "title", "sectionDisplayName"),
        "customTexture":      custom_tex,
        "offerGroupsCount":   offer_groups_count,      # â‘  è¿½åŠ 
        "hasTextureMetadata": has_texture_metadata,    # â‘¡ è¿½åŠ ï¼ˆTrue/Falseï¼‰
        "textureUrls":        texture_urls,            # â‘¡ ä¿å­˜ç”¨URLãƒªã‚¹ãƒˆ
        "stackRankStart":     start_date,
    }

def main():
    r = requests.get(URL, params=PARAMS, headers=HEADERS, timeout=20)
    r.raise_for_status()
    data = r.json()

    sections = dig_for_sections(data)
    if not sections:
        print("ã‚·ãƒ§ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚response.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        with open("response.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        sys.exit(1)

    normalized = [normalize_section(s) for s in sections]

    # å‡ºåŠ›
    # === æ—¥ä»˜ã”ã¨(JSON)ã®åˆ†å‰²å‡ºåŠ› ===
    out_dir = Path("itemshop_by_date")
    out_dir.mkdir(parents=True, exist_ok=True)

    JST = timezone(timedelta(hours=9))  # Asia/Tokyo

    def to_jst_date_str(iso_str: str) -> str | None:
        if not iso_str:
            return None
        try:
            # ä¾‹: "2025-09-19T00:00:00.000Z"
            dt = datetime.fromisoformat(iso_str.replace("Z", "+00:00"))
            dt_jst = dt.astimezone(JST)
            return dt_jst.strftime("%Y-%m-%d")
        except Exception:
            return None

    # æ—¥ä»˜ã”ã¨ã«ã¾ã¨ã‚ã‚‹ï¼ˆstackRankStartãŒç„¡ã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    bucket: dict[str, list] = {}
    for row in normalized:
        d = to_jst_date_str(row.get("stackRankStart"))
        if not d:
            continue
        bucket.setdefault(d, []).append(row)

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›: mp_item_shop_YYYY-MM-DD.json
    generated_at = datetime.now(JST).isoformat()
    for d, rows in bucket.items():
        payload = {
            "date": d,                 # JSTã®æ—¥ä»˜
            "generatedAt": generated_at,
            "count": len(rows),
            "sections": rows,
        }
        with open(out_dir / f"mp_item_shop_{d}.json", "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    print(f"ğŸ—‚ï¸ åˆ†å‰²JSONã‚’æ›¸ãå‡ºã—ã¾ã—ãŸ: {out_dir} ï¼ˆ{len(bucket)}ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")

    import os
    from urllib.parse import urlparse

    # ç”»åƒä¿å­˜ï¼ˆURLåã§ä¿å­˜ï¼‰
    base_dir = Path("itemshop_backgrounds")
    base_dir.mkdir(parents=True, exist_ok=True)

    def url_basename(url: str) -> str:
        path = urlparse(url).path
        fname = os.path.basename(path)
        return fname or "unknown.jpg"

    def section_subdir(row):
        # textureMetadata ãŒã‚ã‚‹å ´åˆã¯ sectionIDï¼ˆã¾ãŸã¯ displayNameï¼‰ã§ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        if row.get("hasTextureMetadata"):
            folder = row.get("sectionId") or row.get("displayName") or "unknown_section"
            folder = "".join(c for c in str(folder) if c not in r'\/:*?"<>|').strip()
            return base_dir / folder
        return base_dir

    def save_url_to(url: str, dest_dir: Path):
        try:
            dest_dir.mkdir(parents=True, exist_ok=True)
            out_path = dest_dir / url_basename(url)
            if out_path.exists():
                return
            resp = requests.get(url, headers=HEADERS, timeout=30)
            resp.raise_for_status()
            with open(out_path, "wb") as f:
                f.write(resp.content)
            print(f"ğŸ–¼ï¸ Saved: {out_path}")
        except Exception as e:
            print(f"[WARN] ç”»åƒä¿å­˜å¤±æ•—: {url} -> {e}")

    for row in normalized:
        dest = section_subdir(row)
        # customTexture ã‚’ä¿å­˜
        if row.get("customTexture"):
            save_url_to(row["customTexture"], dest)
        # textureMetadata ã®URLç¾¤ã‚‚ä¿å­˜
        for tu in row.get("textureUrls", []):
            save_url_to(tu, dest)

    # TSVå‡ºåŠ›ï¼ˆstackRanks ã¯æ—¥ä»˜ã¨å€¤ã‚’ã¾ã¨ã‚ã¦1ã‚»ãƒ«ã«ï¼‰
    with open("shop_sections_with_dates.tsv", "w", encoding="utf-8") as f:
        f.write("sectionId\tdisplayName\tlandingPriority\tsortPriority\tdevName\tcustomTexture\tofferGroupsCount\ttextureMetadata\tstackRankStart\n")
        for row in normalized:
            f.write("\t".join([
                str(row.get("sectionId", "")),
                str(row.get("displayName", "")),
                str(row.get("customTexture", "")),
                str(row.get("offerGroupsCount", "")),         # â‘  è¿½åŠ 
                str(row.get("hasTextureMetadata", "")),       # â‘¡ è¿½åŠ 
                str(row.get("stackRankStart", "")),
            ]) + "\n")

    print("âœ… shop_sections_with_dates.json / shop_sections_with_dates.tsv ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
