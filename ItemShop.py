import json
import sys
import requests
from datetime import datetime, timezone, timedelta
from pathlib import Path

URL = "https://fortnitecontent-website-prod07.ol.epicgames.com/content/api/pages/fortnite-game/mp-item-shop"
PARAMS = {"lang": "ja"}
HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Accept": "application/json"
}

def dig_for_sections(obj):
    if isinstance(obj, dict):
        for k in ["shopSections", "sections", "sectionList", "ShopSections", "shop_sections"]:
            if k in obj and isinstance(obj[k], list):
                return obj[k]
        for v in obj.values():
            res = dig_for_sections(v)
            if res:
                return res
    elif isinstance(obj, list):
        for v in obj:
            res = dig_for_sections(v)
            if res:
                return res
    return None

def normalize_section(sec):
    # ãƒã‚¹ãƒˆï¼ˆsection / contentï¼‰ã‚’å¸å
    base = sec.get("section") or sec.get("content") or sec
    meta = base.get("metadata") or sec.get("metadata") or {}

    get = lambda *keys: next((base[k] for k in keys if isinstance(base, dict) and k in base), None)

    # --- stackRanks ã‚’é›†ç´„ï¼šç›´ä¸‹ / base / metadata / offerGroups[].stackRanks ---
    stackRanks_all = []
    for src in (sec.get("stackRanks"), base.get("stackRanks"), meta.get("stackRanks")):
        if isinstance(src, list):
            stackRanks_all.extend(src)

    # offerGroups å´ã® stackRanks ã‚‚è¿½åŠ 
    og_list = meta.get("offerGroups") or []
    for og in og_list:
        if isinstance(og, dict):
            ranks = og.get("stackRanks")
            if not ranks:
                ranks = (og.get("metadata") or {}).get("stackRanks")
            if isinstance(ranks, list):
                stackRanks_all.extend(ranks)

    # â‘  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® 2023-01-01 ã¯é™¤å¤–
    # â‘  ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® 2023-01-01 ã¯é™¤å¤–ã—ã¤ã¤ã€ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«é–‹å§‹/çµ‚äº†ã‚’æ±ºå®š
    #    ã‚°ãƒ«ãƒ¼ãƒ—ã‚­ãƒ¼: (context, productTag)
    groups = {}
    for s in stackRanks_all:
        sd = s.get("startDate")
        if not sd or sd == "2023-01-01T00:00:00.000Z":
            continue
        key = (s.get("context"), s.get("productTag"))
        groups.setdefault(key, []).append(s)

    parsed_ranks = []
    for key, items in groups.items():
        # ISO8601æ–‡å­—åˆ—ãªã®ã§æ–‡å­—åˆ—ã‚½ãƒ¼ãƒˆã§OKï¼ˆå³å¯†ã«ã™ã‚‹ãªã‚‰ datetime ã«ã—ã¦ã‚‚è‰¯ã„ï¼‰
        items.sort(key=lambda x: x.get("startDate"))
        for i, cur in enumerate(items):
            nxt = items[i + 1] if i + 1 < len(items) else None
            parsed_ranks.append({
                # å‡ºåŠ›ã¯é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã®ã¿ï¼ˆçµ‚äº†æ—¥ã¯æ¬¡ã®é–‹å§‹æ—¥ã€æœ€å¾Œã¯ Noneï¼‰
                "startDate": cur.get("startDate"),
                "endDate":   nxt.get("startDate") if nxt else None,
            })


    # â‘¡ èƒŒæ™¯URLï¼ˆcustomTextureï¼‰
    bg = (meta.get("background") or {})
    custom_tex = bg.get("customTexture")

    # â‘¢ offerGroups ä»¶æ•°ï¼ˆ= ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã‚µãƒ–ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°ï¼‰
    og_list = meta.get("offerGroups") or []
    offer_groups_count = len(og_list)

    # â‘£ textureMetadata ã®æœ‰ç„¡ã¨URLãƒªã‚¹ãƒˆï¼ˆä¿å­˜ç”¨ï¼‰
    texture_urls = []
    for og in og_list:
        md = (og.get("metadata") or {})
        tmetas = md.get("textureMetadata") or []
        for t in tmetas:
            val = t.get("value")
            if isinstance(val, str):
                texture_urls.append(val)
    has_texture_metadata = len(texture_urls) > 0
    # é‡è¤‡é™¤å»
    texture_urls = list(dict.fromkeys(texture_urls))

    # stackRanks ã®é–‹å§‹æ—¥ã ã‘ã‚’1ã¤å–ã‚‹
    start_date = None
    if parsed_ranks:
        try:
            start_date = min(r["startDate"] for r in parsed_ranks if r.get("startDate"))
        except ValueError:
            start_date = None

    return {
        "sectionId":          get("sectionId", "sectionID", "id", "section_id", "name"),
        "displayName":        get("displayName", "title", "sectionDisplayName"),
        "customTexture":      custom_tex,
        "offerGroupsCount":   offer_groups_count,      # â‘  è¿½åŠ 
        "hasTextureMetadata": has_texture_metadata,    # â‘¡ è¿½åŠ ï¼ˆTrue/Falseï¼‰
        "textureUrls":        texture_urls,            # â‘¡ ä¿å­˜ç”¨URLãƒªã‚¹ãƒˆ
        "stackRankStart":     start_date,
    }

def main():
    r = requests.get(URL, params=PARAMS, headers=HEADERS, timeout=20)
    r.raise_for_status()
    data = r.json()

    sections = dig_for_sections(data)
    if not sections:
        print("ã‚·ãƒ§ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚response.jsonã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        with open("response.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        sys.exit(1)

    normalized = [normalize_section(s) for s in sections]

    # å‡ºåŠ›
    # === æ—¥ä»˜ã”ã¨(JSON)ã®åˆ†å‰²å‡ºåŠ› ===
    out_dir = Path("itemshop_by_date")
    out_dir.mkdir(parents=True, exist_ok=True)

    JST = timezone(timedelta(hours=9))  # Asia/Tokyo

    def to_jst_date_str(iso_str: str) -> str | None:
        if not iso_str:
            return None
        try:
            # ä¾‹: "2025-09-19T00:00:00.000Z"
            dt = datetime.fromisoformat(iso_str.replace("Z", "+00:00"))
            dt_jst = dt.astimezone(JST)
            return dt_jst.strftime("%Y-%m-%d")
        except Exception:
            return None

    # æ—¥ä»˜ã”ã¨ã«ã¾ã¨ã‚ã‚‹ï¼ˆstackRankStartãŒç„¡ã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    bucket: dict[str, list] = {}
    for row in normalized:
        d = to_jst_date_str(row.get("stackRankStart"))
        if not d:
            continue
        bucket.setdefault(d, []).append(row)

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›: mp_item_shop_YYYY-MM-DD.json
    generated_at = datetime.now(JST).isoformat()
    for d, rows in bucket.items():
        payload = {
            "date": d,                 # JSTã®æ—¥ä»˜
            "generatedAt": generated_at,
            "count": len(rows),
            "sections": rows,
        }
        with open(out_dir / f"mp_item_shop_{d}.json", "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    print(f"ğŸ—‚ï¸ åˆ†å‰²JSONã‚’æ›¸ãå‡ºã—ã¾ã—ãŸ: {out_dir} ï¼ˆ{len(bucket)}ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")

    import os
    from urllib.parse import urlparse

    # ç”»åƒä¿å­˜ï¼ˆURLåã§ä¿å­˜ï¼‰
    base_dir = Path("itemshop_backgrounds")
    base_dir.mkdir(parents=True, exist_ok=True)

    def url_basename(url: str) -> str:
        path = urlparse(url).path
        fname = os.path.basename(path)
        return fname or "unknown.jpg"

    def section_subdir(row):
        # textureMetadata ãŒã‚ã‚‹å ´åˆã¯ sectionIDï¼ˆã¾ãŸã¯ displayNameï¼‰ã§ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        if row.get("hasTextureMetadata"):
            folder = row.get("sectionId") or row.get("displayName") or "unknown_section"
            folder = "".join(c for c in str(folder) if c not in r'\/:*?"<>|').strip()
            return base_dir / folder
        return base_dir

    def save_url_to(url: str, dest_dir: Path):
        try:
            dest_dir.mkdir(parents=True, exist_ok=True)
            out_path = dest_dir / url_basename(url)
            if out_path.exists():
                return
            resp = requests.get(url, headers=HEADERS, timeout=30)
            resp.raise_for_status()
            with open(out_path, "wb") as f:
                f.write(resp.content)
            print(f"ğŸ–¼ï¸ Saved: {out_path}")
        except Exception as e:
            print(f"[WARN] ç”»åƒä¿å­˜å¤±æ•—: {url} -> {e}")

    for row in normalized:
        dest = section_subdir(row)
        # customTexture ã‚’ä¿å­˜
        if row.get("customTexture"):
            save_url_to(row["customTexture"], dest)
        # textureMetadata ã®URLç¾¤ã‚‚ä¿å­˜
        for tu in row.get("textureUrls", []):
            save_url_to(tu, dest)

    # TSVå‡ºåŠ›ï¼ˆstackRanks ã¯æ—¥ä»˜ã¨å€¤ã‚’ã¾ã¨ã‚ã¦1ã‚»ãƒ«ã«ï¼‰
    with open("shop_sections_with_dates.tsv", "w", encoding="utf-8") as f:
        f.write("sectionId\tdisplayName\tlandingPriority\tsortPriority\tdevName\tcustomTexture\tofferGroupsCount\ttextureMetadata\tstackRankStart\n")
        for row in normalized:
            f.write("\t".join([
                str(row.get("sectionId", "")),
                str(row.get("displayName", "")),
                str(row.get("customTexture", "")),
                str(row.get("offerGroupsCount", "")),         # â‘  è¿½åŠ 
                str(row.get("hasTextureMetadata", "")),       # â‘¡ è¿½åŠ 
                str(row.get("stackRankStart", "")),
            ]) + "\n")

    print("âœ… shop_sections_with_dates.json / shop_sections_with_dates.tsv ã‚’å‡ºåŠ›ã—ã¾ã—ãŸã€‚")

    for row in normalized:
        create_section_image(row, Path("itemshop_section_images"))

from PIL import Image, ImageDraw, ImageFont
import io

FONT_PATH = "c:/USERS/FN_GREENFOX/APPDATA/LOCAL/MICROSOFT/WINDOWS/FONTS/NOTOSANSJP-BOLD.OTF"  # æ—¥æœ¬èªè¡¨ç¤ºç”¨

from PIL import Image, ImageDraw, ImageFont, ImageFilter
import io, math, textwrap

FONT_PATH_TITLE = FONT_PATH  # ã‚¿ã‚¤ãƒˆãƒ«ç”¨ï¼ˆå¿…è¦ãªã‚‰å¤ªå­—ãƒ•ã‚©ãƒ³ãƒˆã«å¤‰æ›´ï¼‰
FONT_PATH_INFO  = FONT_PATH  # æƒ…å ±ç”¨

def _wrap_text(draw, text, font, max_width):
    """max_width ã‚’è¶…ãˆãªã„ã‚ˆã†ã«æ—¥æœ¬èªã‚‚ã–ã£ãã‚ŠæŠ˜ã‚Šè¿”ã—"""
    # textwrap ã¯è‹±èªå‘ã‘ã ãŒã€å¹…ã§è½ã¡ã‚„ã™ã„ã‚ˆã†çŸ­ã‚ã§æŠ˜ã‚‹
    lines = []
    if not text:
        return [""]
    # ã¾ãšé©å½“ãªç›®å®‰ã§å¹…æ¨å®š â†’ å°‘ã—ãšã¤è©°ã‚ã‚‹
    est = max(8, min(len(text), 28))
    for trial in range(est, 4, -1):
        test = textwrap.wrap(text, width=trial, break_long_words=True, drop_whitespace=False)
        if all(draw.textlength(t, font=font) <= max_width for t in test):
            lines = test
            break
    if not lines:
        # æœ€å¾Œã®ç ¦ï¼š1æ–‡å­—ãšã¤ç©ã‚“ã§æŠ˜ã‚Šè¿”ã—
        cur = ""
        for ch in text:
            if draw.textlength(cur + ch, font=font) <= max_width:
                cur += ch
            else:
                lines.append(cur)
                cur = ch
        if cur:
            lines.append(cur)
    return lines

def create_section_image(row, out_dir: Path):
    bg_url = row.get("customTexture")
    if not bg_url:
        return

    # ==== èƒŒæ™¯å–å¾— & ãƒªã‚µã‚¤ã‚º ====
    try:
        resp = requests.get(bg_url, headers=HEADERS, timeout=30)
        resp.raise_for_status()
        bg_img = Image.open(io.BytesIO(resp.content)).convert("RGBA")
        bg_img = bg_img.resize((750, 422), Image.LANCZOS)
    except Exception as e:
        print(f"[WARN] èƒŒæ™¯å–å¾—å¤±æ•—: {bg_url} -> {e}")
        return

    W, H = 750, 422

    # ==== ä¸Šã‹ã‚‰ä¸‹ã«é»’ãƒ•ã‚§ãƒ¼ãƒ‰ ====
    grad = Image.new("L", (1, H))
    for y in range(H):
        alpha = int((y / H) * 200)  # ä¸‹ã«è¡Œãã»ã©æ¿ƒã
        grad.putpixel((0, y), alpha)
    grad = grad.resize((W, H))
    fade = Image.new("RGBA", (W, H), (0, 0, 0, 255))
    bg_img = Image.alpha_composite(bg_img, Image.merge("RGBA", (*fade.split()[:3], grad)))

    draw = ImageDraw.Draw(bg_img)

    # ==== ãƒ•ã‚©ãƒ³ãƒˆ ====
    try:
        font_title = ImageFont.truetype(FONT_PATH_TITLE, 56)
        font_info  = ImageFont.truetype(FONT_PATH_INFO, 32)
    except Exception:
        font_title = font_info = ImageFont.load_default()

    # ==== æ—¥ä»˜å¤‰æ› ====
    release_fmt = "-"
    raw = row.get("stackRankStart", "")
    if raw:
        try:
            dt = datetime.fromisoformat(raw.replace("Z", "+00:00"))
            dt_jst = dt.astimezone(timezone(timedelta(hours=9)))
            release_fmt = f"{dt_jst.month}æœˆ{dt_jst.day}æ—¥"
        except Exception:
            release_fmt = raw

    # ==== ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™ ====
    display_name = row.get("displayName") or "ç„¡é¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³"
    section_id   = row.get("sectionId") or "unknown_id"
    groups_cnt   = int(row.get("offerGroupsCount") or 0)

    # ==== ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¸­å¤®ä¸Šéƒ¨ã€å¤§ããï¼‰====
    tw = draw.textlength(display_name, font=font_title)
    draw.text(((W - tw) // 2, 28), display_name, font=font_title,
              fill=(255, 255, 255, 240), stroke_width=3, stroke_fill=(0, 0, 0, 200))

    # ==== ä¸­å¤®ã«åŠé€æ˜ãƒ‘ãƒãƒ« ====
    panel_w, panel_h = W - 80, 120
    panel_x, panel_y = (W - panel_w)//2, (H - panel_h)//2
    panel = Image.new("RGBA", (W, H), (0,0,0,0))
    pdraw = ImageDraw.Draw(panel)
    pdraw.rounded_rectangle((panel_x, panel_y, panel_x+panel_w, panel_y+panel_h),
                            radius=20, fill=(0,0,0,160))
    bg_img = Image.alpha_composite(bg_img, panel)
    draw = ImageDraw.Draw(bg_img)

    # ==== æƒ…å ±3è¡Œ ====
    info_lines = [
        f"ğŸ†” {section_id}",
        f"#ï¸âƒ£ {groups_cnt} ã‚»ã‚¯ã‚·ãƒ§ãƒ³",
        f"ğŸ“… {release_fmt}",
    ]
    iy = panel_y + 20
    for line in info_lines:
        draw.text((panel_x+30, iy), line, font=font_info,
                  fill=(255,255,255,240), stroke_width=2, stroke_fill=(0,0,0,180))
        iy += font_info.size + 10

    # ==== å¤–æ  ====
    border = ImageDraw.Draw(bg_img)
    border.rounded_rectangle((4,4,W-4,H-4), radius=24,
                             outline=(255,255,255,60), width=3)

    # ==== ä¿å­˜ ====
    out_dir.mkdir(parents=True, exist_ok=True)
    fname = "".join(c for c in f"{section_id or display_name}.png" if c not in r'\/:*?\"<>|')
    final_path = out_dir / fname
    tmp_path = final_path.with_name(final_path.name + ".__tmp")
    try:
        bg_img.save(tmp_path, format="PNG")
        tmp_path.replace(final_path)
    finally:
        if tmp_path.exists():
            try: tmp_path.unlink()
            except: pass
    print(f"ğŸ–¼ï¸ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {final_path}")

if __name__ == "__main__":
    main()
